{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bankruptcy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM4Ey6+dzqjD8dFxu6pX7oS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/M0hammad-Kashif/Notebooks/blob/main/Bankruptcy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%capture\n",
        "# To supress warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "# Basic Libraries for Data organization, Statistical operations and Plotting\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "# For loading .arff files\n",
        "from scipy.io import arff\n",
        "# To analyze the type of missing data\n",
        "import missingno as msno\n",
        "# Library for performing k-NN and MICE imputations \n",
        "!pip install fancyimpute\n",
        "import fancyimpute\n",
        "# Library to perform Expectation-Maximization (EM) imputation\n",
        "!pip install impyute\n",
        "import impyute as impy\n",
        "# To perform mean imputation\n",
        "from sklearn.impute import SimpleImputer\n",
        "#To perform kFold Cross Validation\n",
        "from sklearn.model_selection import KFold\n",
        "# Formatted counter of class labels\n",
        "from collections import Counter\n",
        "# Ordered Dictionary\n",
        "from collections import OrderedDict\n",
        "# Library imbalanced-learn to deal with the data imbalance. To use SMOTE oversampling\n",
        "from imblearn.over_sampling import SMOTE \n",
        "\n",
        "# Impoting classification models\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from imblearn.ensemble import BalancedBaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "import random\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import precision_recall_curve"
      ],
      "metadata": {
        "id": "Wxf-r_W3QzqK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52215a21-56d5-4bd4-d800-085ded517605"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fancyimpute in /usr/local/lib/python3.7/dist-packages (0.7.0)\n",
            "Requirement already satisfied: scikit-learn>=0.24.2 in /usr/local/lib/python3.7/dist-packages (from fancyimpute) (1.0.2)\n",
            "Requirement already satisfied: cvxopt in /usr/local/lib/python3.7/dist-packages (from fancyimpute) (1.2.7)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from fancyimpute) (3.6.4)\n",
            "Requirement already satisfied: knnimpute>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from fancyimpute) (0.1.0)\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.7/dist-packages (from fancyimpute) (1.3.7)\n",
            "Requirement already satisfied: cvxpy in /usr/local/lib/python3.7/dist-packages (from fancyimpute) (1.0.31)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from knnimpute>=0.1.0->fancyimpute) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.7/dist-packages (from knnimpute>=0.1.0->fancyimpute) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.2->fancyimpute) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.2->fancyimpute) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.2->fancyimpute) (1.4.1)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.7/dist-packages (from cvxpy->fancyimpute) (2.0.10)\n",
            "Requirement already satisfied: scs>=1.1.3 in /usr/local/lib/python3.7/dist-packages (from cvxpy->fancyimpute) (3.2.0)\n",
            "Requirement already satisfied: osqp>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from cvxpy->fancyimpute) (0.6.2.post0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from cvxpy->fancyimpute) (0.70.12.2)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.7/dist-packages (from osqp>=0.4.1->cvxpy->fancyimpute) (0.1.5.post2)\n",
            "Requirement already satisfied: dill>=0.3.4 in /usr/local/lib/python3.7/dist-packages (from multiprocess->cvxpy->fancyimpute) (0.3.4)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->fancyimpute) (8.12.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->fancyimpute) (21.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytest->fancyimpute) (57.4.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->fancyimpute) (1.11.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->fancyimpute) (0.7.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->fancyimpute) (1.4.0)\n",
            "Requirement already satisfied: impyute in /usr/local/lib/python3.7/dist-packages (0.0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from impyute) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from impyute) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from impyute) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->impyute) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->impyute) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "############################################################\n",
        "# Loads the 5 raw .arff files into a list\n",
        "def load_arff_raw_data():\n",
        "    N=5\n",
        "    return [arff.loadarff('/content/' + str(i+1) + 'year.arff') for i in range(N)]\n",
        "\n",
        "############################################################\n",
        "# Loads the 5 raw .arff files into pandas dataframes\n",
        "def load_dataframes():\n",
        "    return [pd.DataFrame(data_i_year[0]) for data_i_year in load_arff_raw_data()]\n",
        "\n",
        "############################################################\n",
        "# Set the column headers from X1 ... X64 and the class label as Y, for all the 5 dataframes.\n",
        "def set_new_headers(dataframes):\n",
        "    cols = ['X' + str(i+1) for i in range(len(dataframes[0].columns)-1)]\n",
        "    cols.append('Y')\n",
        "    for df in dataframes:\n",
        "        df.columns = cols\n",
        "\n",
        "############################################################\n",
        "# dataframes is the list of pandas dataframes for the 5 year datafiles.  \n",
        "dataframes = load_dataframes()\n",
        "\n",
        "# Set the new headers for the dataframes. The new headers will have the renamed set of feature (X1 to X64)\n",
        "set_new_headers(dataframes)    \n",
        "\n",
        "# print the first 5 rows of a dataset 'year1'\n",
        "dataframes[0].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "_zsWnPPKRR4_",
        "outputId": "51e2c080-c92e-47bb-8564-4e7aea08dbed"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         X1       X2       X3      X4       X5       X6        X7       X8  \\\n",
              "0  0.200550  0.37951  0.39641  2.0472  32.3510  0.38825  0.249760  1.33050   \n",
              "1  0.209120  0.49988  0.47225  1.9447  14.7860  0.00000  0.258340  0.99601   \n",
              "2  0.248660  0.69592  0.26713  1.5548  -1.1523  0.00000  0.309060  0.43695   \n",
              "3  0.081483  0.30734  0.45879  2.4928  51.9520  0.14988  0.092704  1.86610   \n",
              "4  0.187320  0.61323  0.22960  1.4063  -7.3128  0.18732  0.187320  0.63070   \n",
              "\n",
              "       X9      X10  ...       X56      X57      X58       X59     X60     X61  \\\n",
              "0  1.1389  0.50494  ...  0.121960  0.39718  0.87804  0.001924  8.4160  5.1372   \n",
              "1  1.6996  0.49788  ...  0.121300  0.42002  0.85300  0.000000  4.1486  3.2732   \n",
              "2  1.3090  0.30408  ...  0.241140  0.81774  0.76599  0.694840  4.9909  3.9510   \n",
              "3  1.0571  0.57353  ...  0.054015  0.14207  0.94598  0.000000  4.5746  3.6147   \n",
              "4  1.1559  0.38677  ...  0.134850  0.48431  0.86515  0.124440  6.3985  4.3158   \n",
              "\n",
              "       X62     X63      X64     Y  \n",
              "0   82.658  4.4158   7.4277  b'0'  \n",
              "1  107.350  3.4000  60.9870  b'0'  \n",
              "2  134.270  2.7185   5.2078  b'0'  \n",
              "3   86.435  4.2228   5.5497  b'0'  \n",
              "4  127.210  2.8692   7.8980  b'0'  \n",
              "\n",
              "[5 rows x 65 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6e27f7ff-9a74-4f05-a379-37f9c0da2318\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X1</th>\n",
              "      <th>X2</th>\n",
              "      <th>X3</th>\n",
              "      <th>X4</th>\n",
              "      <th>X5</th>\n",
              "      <th>X6</th>\n",
              "      <th>X7</th>\n",
              "      <th>X8</th>\n",
              "      <th>X9</th>\n",
              "      <th>X10</th>\n",
              "      <th>...</th>\n",
              "      <th>X56</th>\n",
              "      <th>X57</th>\n",
              "      <th>X58</th>\n",
              "      <th>X59</th>\n",
              "      <th>X60</th>\n",
              "      <th>X61</th>\n",
              "      <th>X62</th>\n",
              "      <th>X63</th>\n",
              "      <th>X64</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.200550</td>\n",
              "      <td>0.37951</td>\n",
              "      <td>0.39641</td>\n",
              "      <td>2.0472</td>\n",
              "      <td>32.3510</td>\n",
              "      <td>0.38825</td>\n",
              "      <td>0.249760</td>\n",
              "      <td>1.33050</td>\n",
              "      <td>1.1389</td>\n",
              "      <td>0.50494</td>\n",
              "      <td>...</td>\n",
              "      <td>0.121960</td>\n",
              "      <td>0.39718</td>\n",
              "      <td>0.87804</td>\n",
              "      <td>0.001924</td>\n",
              "      <td>8.4160</td>\n",
              "      <td>5.1372</td>\n",
              "      <td>82.658</td>\n",
              "      <td>4.4158</td>\n",
              "      <td>7.4277</td>\n",
              "      <td>b'0'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.209120</td>\n",
              "      <td>0.49988</td>\n",
              "      <td>0.47225</td>\n",
              "      <td>1.9447</td>\n",
              "      <td>14.7860</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.258340</td>\n",
              "      <td>0.99601</td>\n",
              "      <td>1.6996</td>\n",
              "      <td>0.49788</td>\n",
              "      <td>...</td>\n",
              "      <td>0.121300</td>\n",
              "      <td>0.42002</td>\n",
              "      <td>0.85300</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.1486</td>\n",
              "      <td>3.2732</td>\n",
              "      <td>107.350</td>\n",
              "      <td>3.4000</td>\n",
              "      <td>60.9870</td>\n",
              "      <td>b'0'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.248660</td>\n",
              "      <td>0.69592</td>\n",
              "      <td>0.26713</td>\n",
              "      <td>1.5548</td>\n",
              "      <td>-1.1523</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.309060</td>\n",
              "      <td>0.43695</td>\n",
              "      <td>1.3090</td>\n",
              "      <td>0.30408</td>\n",
              "      <td>...</td>\n",
              "      <td>0.241140</td>\n",
              "      <td>0.81774</td>\n",
              "      <td>0.76599</td>\n",
              "      <td>0.694840</td>\n",
              "      <td>4.9909</td>\n",
              "      <td>3.9510</td>\n",
              "      <td>134.270</td>\n",
              "      <td>2.7185</td>\n",
              "      <td>5.2078</td>\n",
              "      <td>b'0'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.081483</td>\n",
              "      <td>0.30734</td>\n",
              "      <td>0.45879</td>\n",
              "      <td>2.4928</td>\n",
              "      <td>51.9520</td>\n",
              "      <td>0.14988</td>\n",
              "      <td>0.092704</td>\n",
              "      <td>1.86610</td>\n",
              "      <td>1.0571</td>\n",
              "      <td>0.57353</td>\n",
              "      <td>...</td>\n",
              "      <td>0.054015</td>\n",
              "      <td>0.14207</td>\n",
              "      <td>0.94598</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.5746</td>\n",
              "      <td>3.6147</td>\n",
              "      <td>86.435</td>\n",
              "      <td>4.2228</td>\n",
              "      <td>5.5497</td>\n",
              "      <td>b'0'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.187320</td>\n",
              "      <td>0.61323</td>\n",
              "      <td>0.22960</td>\n",
              "      <td>1.4063</td>\n",
              "      <td>-7.3128</td>\n",
              "      <td>0.18732</td>\n",
              "      <td>0.187320</td>\n",
              "      <td>0.63070</td>\n",
              "      <td>1.1559</td>\n",
              "      <td>0.38677</td>\n",
              "      <td>...</td>\n",
              "      <td>0.134850</td>\n",
              "      <td>0.48431</td>\n",
              "      <td>0.86515</td>\n",
              "      <td>0.124440</td>\n",
              "      <td>6.3985</td>\n",
              "      <td>4.3158</td>\n",
              "      <td>127.210</td>\n",
              "      <td>2.8692</td>\n",
              "      <td>7.8980</td>\n",
              "      <td>b'0'</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 65 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e27f7ff-9a74-4f05-a379-37f9c0da2318')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6e27f7ff-9a74-4f05-a379-37f9c0da2318 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6e27f7ff-9a74-4f05-a379-37f9c0da2318');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(dataframes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0QVrqXASgim",
        "outputId": "3c24ce51-ebb8-439e-d561-af5022910040"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(dataframes)):\n",
        "  print(f\"Length of {i+1} dataframe {len(dataframes[0])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAZxl9ubVXmq",
        "outputId": "41e1e253-06a1-4014-d084-345c5896b57e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of 1 dataframe 7027\n",
            "Length of 2 dataframe 7027\n",
            "Length of 3 dataframe 7027\n",
            "Length of 4 dataframe 7027\n",
            "Length of 5 dataframe 7027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the dtypes of all the columns (other than the class label columns) to float.\n",
        "def convert_columns_type_float(dfs):\n",
        "    for i in range(5):\n",
        "        index = 1\n",
        "        while(index<=63):\n",
        "            colname = dfs[i].columns[index]\n",
        "            col = getattr(dfs[i], colname)\n",
        "            dfs[i][colname] = col.astype(float)\n",
        "            index+=1\n",
        "            \n",
        "convert_columns_type_float(dataframes)  "
      ],
      "metadata": {
        "id": "pRC1_HlyS6N6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(dataframes)):\n",
        "  print(f\"Unique columns in year {i+1} is {dataframes[i]['Y'].unique()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPeNnaYCTTGE",
        "outputId": "4775d207-b945-430b-c896-bc41ff264569"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique columns in year 1 is [b'0' b'1']\n",
            "Unique columns in year 2 is [b'0' b'1']\n",
            "Unique columns in year 3 is [b'0' b'1']\n",
            "Unique columns in year 4 is [b'0' b'1']\n",
            "Unique columns in year 5 is [b'0' b'1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The class labels for all the dataframes are originally in object type.\n",
        "# Convert them to int types\n",
        "def convert_class_label_type_int(dfs):\n",
        "    for i in range(len(dfs)):\n",
        "        col = getattr(dfs[i], 'Y')\n",
        "        dfs[i]['Y'] = col.astype(int)\n",
        "        \n",
        "convert_class_label_type_int(dataframes)"
      ],
      "metadata": {
        "id": "HpA0Lf9KT55O"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################################################\n",
        "# Get Clean dataframes by dropping all the rows which have missing values\n",
        "def drop_nan_rows(dataframes, verbose=False):\n",
        "    clean_dataframes = [df.dropna(axis=0, how='any') for df in dataframes]\n",
        "    if verbose:\n",
        "        for i in range(len(dataframes)):\n",
        "            print(str(i+1)+'year:','Original Length=', len(dataframes[i]), '\\tCleaned Length=', len(clean_dataframes[i]), '\\tMissing Data=', len(dataframes[i])-len(clean_dataframes[i]))\n",
        "    return clean_dataframes\n",
        "\n",
        "# Doing a quick analysis of how many missing values are there in each of the 5 dataframes\n",
        "nan_dropped_dataframes = drop_nan_rows(dataframes, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0_9GSA6UDbP",
        "outputId": "15691dbb-2dc7-4967-e253-7b3af7dce125"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1year: Original Length= 7027 \tCleaned Length= 3194 \tMissing Data= 3833\n",
            "2year: Original Length= 10173 \tCleaned Length= 4088 \tMissing Data= 6085\n",
            "3year: Original Length= 10503 \tCleaned Length= 4885 \tMissing Data= 5618\n",
            "4year: Original Length= 9792 \tCleaned Length= 4769 \tMissing Data= 5023\n",
            "5year: Original Length= 5910 \tCleaned Length= 3031 \tMissing Data= 2879\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate the sparsity matrix (figure) for all the dataframes\n",
        "def generate_sparsity_matrix(dfs):\n",
        "    for i in range(5):\n",
        "        missing_df_i = dfs[i].columns[dfs[i].isnull().any()].tolist()\n",
        "        msno.matrix(dfs[i][missing_df_i], figsize=(20,5))\n",
        "\n",
        "generate_sparsity_matrix(dataframes)"
      ],
      "metadata": {
        "id": "fL8TyzdNUHP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate the heatmap for all the dataframes\n",
        "def generate_heatmap(dfs):\n",
        "    for i in range(5):\n",
        "        missing_df_i = dfs[i].columns[dfs[i].isnull().any()].tolist()\n",
        "        msno.heatmap(dfs[i][missing_df_i], figsize=(20,20))\n",
        "        \n",
        "generate_heatmap(dataframes) "
      ],
      "metadata": {
        "id": "xYGX_THxUOL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_mean_imputation(dfs):\n",
        "    # Construct an imputer with strategy as 'mean', to mean-impute along the columns\n",
        "    imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "    mean_imputed_dfs = [pd.DataFrame(imputer.fit_transform(df)) for df in dfs]\n",
        "    for i in range(len(dfs)):\n",
        "        mean_imputed_dfs[i].columns = dfs[i].columns   \n",
        "    return mean_imputed_dfs\n",
        "\n",
        "mean_imputed_dataframes = perform_mean_imputation(dataframes)"
      ],
      "metadata": {
        "id": "lODr4g2lUZS6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bu7CxpYdUiCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "def perform_knn_imputation(dfs):\n",
        "    knn_imputed_datasets = [fancyimpute.KNN(k=100,verbose=True).fit_transform(dfs[i]) for i in range(len(dfs))]\n",
        "    # X_filled_knn = KNN(k=3).fit_transform(df_OppLine[['family']])\n",
        "    return [pd.DataFrame(data=knn_imputed_datasets[i]) for i in range(len(dfs))]\n",
        "    \n",
        "knn_imputed_dataframes = perform_knn_imputation(dataframes)\n",
        "set_new_headers(knn_imputed_dataframes)"
      ],
      "metadata": {
        "id": "hJMIDKAkU5xR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_EM_imputation(dfs):\n",
        "    em_imputed_datasets = [ impy.imputation.cs.em(dfs[i].values, loops=50) for i in range(len(dfs))]\n",
        "    return [pd.DataFrame(data=em_imputed_datasets[i]) for i in range(len(dfs))]\n",
        "\n",
        "em_imputed_dataframes = perform_EM_imputation(dataframes)\n",
        "set_new_headers(em_imputed_dataframes)"
      ],
      "metadata": {
        "id": "KS6ekv9RVhac"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kJzv5HOuXGk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtaining the completed features for all the 5 dataframes by doing MICE (Multiple Imputation from Chained Equations)\n",
        "\n",
        "from fancyimpute import IterativeImputer as MICE\n",
        "\n",
        "# MICE().fit_transform(df)\n",
        "def perform_MICE_imputation(dfs):\n",
        "    mice_imputed_datasets = [MICE().fit_transform(dfs[i]) for i in range(len(dfs))]\n",
        "    return [pd.DataFrame(data=mice_imputed_datasets[i]) for i in range(len(dfs))]\n",
        "    \n",
        "mice_imputed_dataframes = perform_MICE_imputation(dataframes)\n",
        "set_new_headers(mice_imputed_dataframes)"
      ],
      "metadata": {
        "id": "SWZXJODzV_wl"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "imputed_dataframes_dictionary = OrderedDict()\n",
        "imputed_dataframes_dictionary['Mean'] = mean_imputed_dataframes\n",
        "imputed_dataframes_dictionary['k-NN'] = knn_imputed_dataframes\n",
        "imputed_dataframes_dictionary['EM'] = em_imputed_dataframes\n",
        "# imputed_dataframes_dictionary['MICE'] = mice_imputed_dataframes"
      ],
      "metadata": {
        "id": "k4ihIqNzWDZi"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_data_imbalance(dfs):\n",
        "    for i in range(len(dfs)):\n",
        "        print('Dataset: '+str(i+1)+'year')\n",
        "        print(dfs[i].groupby('Y').size())\n",
        "        minority_percent = (dfs[i]['Y'].tolist().count(1) / len(dfs[i]['Y'].tolist()))*100\n",
        "        print('Minority (label 1) percentage: '+  str(minority_percent) + '%')\n",
        "        print('-'*64)\n",
        "        \n",
        "check_data_imbalance(dataframes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUKwzBXwWGV5",
        "outputId": "dadcbe77-7311-429a-c31f-d8f9f1350c6d"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: 1year\n",
            "Y\n",
            "0    6756\n",
            "1     271\n",
            "dtype: int64\n",
            "Minority (label 1) percentage: 3.856553294435748%\n",
            "----------------------------------------------------------------\n",
            "Dataset: 2year\n",
            "Y\n",
            "0    9773\n",
            "1     400\n",
            "dtype: int64\n",
            "Minority (label 1) percentage: 3.931976801336872%\n",
            "----------------------------------------------------------------\n",
            "Dataset: 3year\n",
            "Y\n",
            "0    10008\n",
            "1      495\n",
            "dtype: int64\n",
            "Minority (label 1) percentage: 4.712939160239932%\n",
            "----------------------------------------------------------------\n",
            "Dataset: 4year\n",
            "Y\n",
            "0    9277\n",
            "1     515\n",
            "dtype: int64\n",
            "Minority (label 1) percentage: 5.259395424836601%\n",
            "----------------------------------------------------------------\n",
            "Dataset: 5year\n",
            "Y\n",
            "0    5500\n",
            "1     410\n",
            "dtype: int64\n",
            "Minority (label 1) percentage: 6.937394247038917%\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the features and labels into separate dataframes for all the original dataframes\n",
        "def split_dataframes_features_labels(dfs):\n",
        "    feature_dfs = [dfs[i].iloc[:,0:64] for i in range(len(dfs))]\n",
        "    label_dfs = [dfs[i].iloc[:,64] for i in range(len(dfs))]\n",
        "    return feature_dfs, label_dfs\n",
        "\n",
        "# Performs the SMOTE oversampling fro given dataframes.\n",
        "def oversample_data_SMOTE(dfs, verbose=False):\n",
        "    smote = SMOTE( random_state=42, k_neighbors=10)\n",
        "    #Split the features and labels for each dataframe\n",
        "    feature_dfs, label_dfs = split_dataframes_features_labels(dfs)\n",
        "    resampled_feature_arrays = []\n",
        "    resampled_label_arrays = []\n",
        "    for i in range(len(dfs)):\n",
        "        if verbose: print('Dataset: ' + str(i+1) + 'year:')\n",
        "        if verbose: print('Original dataset shape {}'.format(Counter(label_dfs[i])))\n",
        "        dfi_features_res, dfi_label_res = smote.fit_resample(feature_dfs[i], label_dfs[i])\n",
        "        if verbose: print('Resampled dataset shape {}\\n'.format(Counter(dfi_label_res)))\n",
        "        # Append the resampled feature and label arrays of ith dataframe to their respective list of arrays    \n",
        "        resampled_feature_arrays.append(dfi_features_res)\n",
        "        resampled_label_arrays.append(dfi_label_res)        \n",
        "    return resampled_feature_arrays, resampled_label_arrays\n",
        "\n",
        "# Utility Function to convert the arrays of features and labels to pandas dataframes, and then join them.\n",
        "# Also re-assign the columns headers.\n",
        "def restructure_arrays_to_dataframes(feature_arrays, label_arrays):\n",
        "    resampled_dfs = []\n",
        "    for i in range(len(feature_arrays)):\n",
        "        feature_df = pd.DataFrame(data=feature_arrays[i])\n",
        "        label_df = pd.DataFrame(data=label_arrays[i])\n",
        "        # Must set the column header for label_df, otherwise it wont join with feature_df, as columns overlap (with col names '0')\n",
        "        label_df.columns=['Y'] \n",
        "        resampled_dfs.append(feature_df.join(label_df))\n",
        "    # re-assign the column headers for features and labels    \n",
        "    set_new_headers(resampled_dfs)    \n",
        "    return resampled_dfs\n",
        "\n",
        "# Perform SMOTE oversampling on all the imputed dataframes, and return them in a dictionary.\n",
        "def perform_oversampling_on_imputed_dataframes(df_dict):\n",
        "    imputed_oversampled_dataframes_dictionary = OrderedDict()\n",
        "    for key,dfs in df_dict.items():\n",
        "        print('SMOTE Oversampling for ' + key + ' imputed dataframes\\n')\n",
        "        smote_feature_arrays, smote_label_arrays = oversample_data_SMOTE(dfs, verbose=True)\n",
        "        oversampled_dataframes = restructure_arrays_to_dataframes(smote_feature_arrays, smote_label_arrays)\n",
        "        imputed_oversampled_dataframes_dictionary[key] = oversampled_dataframes\n",
        "        print('-'*100)\n",
        "    return imputed_oversampled_dataframes_dictionary\n",
        "\n",
        "imputed_oversampled_dataframes_dictionary = perform_oversampling_on_imputed_dataframes(imputed_dataframes_dictionary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjV9ei1nWJ_F",
        "outputId": "b410d352-d37e-48ca-c5e9-b83b17ecdce7"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SMOTE Oversampling for Mean imputed dataframes\n",
            "\n",
            "Dataset: 1year:\n",
            "Original dataset shape Counter({0.0: 6756, 1.0: 271})\n",
            "Resampled dataset shape Counter({0.0: 6756, 1.0: 6756})\n",
            "\n",
            "Dataset: 2year:\n",
            "Original dataset shape Counter({0.0: 9773, 1.0: 400})\n",
            "Resampled dataset shape Counter({0.0: 9773, 1.0: 9773})\n",
            "\n",
            "Dataset: 3year:\n",
            "Original dataset shape Counter({0.0: 10008, 1.0: 495})\n",
            "Resampled dataset shape Counter({0.0: 10008, 1.0: 10008})\n",
            "\n",
            "Dataset: 4year:\n",
            "Original dataset shape Counter({0.0: 9277, 1.0: 515})\n",
            "Resampled dataset shape Counter({0.0: 9277, 1.0: 9277})\n",
            "\n",
            "Dataset: 5year:\n",
            "Original dataset shape Counter({0.0: 5500, 1.0: 410})\n",
            "Resampled dataset shape Counter({0.0: 5500, 1.0: 5500})\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "SMOTE Oversampling for k-NN imputed dataframes\n",
            "\n",
            "Dataset: 1year:\n",
            "Original dataset shape Counter({0.0: 6756, 1.0: 271})\n",
            "Resampled dataset shape Counter({0.0: 6756, 1.0: 6756})\n",
            "\n",
            "Dataset: 2year:\n",
            "Original dataset shape Counter({0.0: 9773, 1.0: 400})\n",
            "Resampled dataset shape Counter({0.0: 9773, 1.0: 9773})\n",
            "\n",
            "Dataset: 3year:\n",
            "Original dataset shape Counter({0.0: 10008, 1.0: 495})\n",
            "Resampled dataset shape Counter({0.0: 10008, 1.0: 10008})\n",
            "\n",
            "Dataset: 4year:\n",
            "Original dataset shape Counter({0.0: 9277, 1.0: 515})\n",
            "Resampled dataset shape Counter({0.0: 9277, 1.0: 9277})\n",
            "\n",
            "Dataset: 5year:\n",
            "Original dataset shape Counter({0.0: 5500, 1.0: 410})\n",
            "Resampled dataset shape Counter({0.0: 5500, 1.0: 5500})\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "SMOTE Oversampling for EM imputed dataframes\n",
            "\n",
            "Dataset: 1year:\n",
            "Original dataset shape Counter({0.0: 6756, 1.0: 271})\n",
            "Resampled dataset shape Counter({0.0: 6756, 1.0: 6756})\n",
            "\n",
            "Dataset: 2year:\n",
            "Original dataset shape Counter({0.0: 9773, 1.0: 400})\n",
            "Resampled dataset shape Counter({0.0: 9773, 1.0: 9773})\n",
            "\n",
            "Dataset: 3year:\n",
            "Original dataset shape Counter({0.0: 10008, 1.0: 495})\n",
            "Resampled dataset shape Counter({0.0: 10008, 1.0: 10008})\n",
            "\n",
            "Dataset: 4year:\n",
            "Original dataset shape Counter({0.0: 9277, 1.0: 515})\n",
            "Resampled dataset shape Counter({0.0: 9277, 1.0: 9277})\n",
            "\n",
            "Dataset: 5year:\n",
            "Original dataset shape Counter({0.0: 5500, 1.0: 410})\n",
            "Resampled dataset shape Counter({0.0: 5500, 1.0: 5500})\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_kfold_cv_data(k, X, y, verbose=False):\n",
        "    X = X.values\n",
        "    y = y.values\n",
        "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "    X_train = []\n",
        "    y_train = []\n",
        "    X_test = []\n",
        "    y_test = []\n",
        "    \n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train.append(X[train_index])\n",
        "        y_train.append(y[train_index])\n",
        "        X_test.append(X[test_index])\n",
        "        y_test.append(y[test_index])\n",
        "    return X_train, y_train, X_test, y_test"
      ],
      "metadata": {
        "id": "BmUR2O4EWS6g"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gaussian Naive Bayes classifier\n",
        "gnb_classifier = GaussianNB()"
      ],
      "metadata": {
        "id": "JDeomE2AWZ2L"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression classifier\n",
        "lr_classifier = LogisticRegression(penalty = 'l2', random_state = 0)"
      ],
      "metadata": {
        "id": "A1tvrplyWbjH"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Decision Tree Classifier\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)"
      ],
      "metadata": {
        "id": "b5_pXjksWeAP"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators = 5, criterion = 'entropy')"
      ],
      "metadata": {
        "id": "TX-ggCF6WgT3"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# eXtreme Gradient Boosting Classifier (XGBClassifier)\n",
        "xgb_classifier = XGBClassifier()"
      ],
      "metadata": {
        "id": "Oj8d6LzkWi-O"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Balanced Bagging Classifier\n",
        "bb_classifier = BalancedBaggingClassifier(base_estimator = RandomForestClassifier(criterion='entropy'))"
      ],
      "metadata": {
        "id": "c_b-vMKpcFHq"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a dictionary of models\n",
        "models_dictionary = OrderedDict()\n",
        "\n",
        "models_dictionary['Gaussian Naive Bayes'] = gnb_classifier\n",
        "models_dictionary['Logistic Regression'] = lr_classifier\n",
        "models_dictionary['Decision Tree'] = dt_classifier\n",
        "models_dictionary['Extreme Gradient Boosting'] = xgb_classifier\n",
        "models_dictionary['Random Forest'] = rf_classifier\n",
        "# models_dictionary['Balanced Bagging'] = bb_classifier"
      ],
      "metadata": {
        "id": "nEsfjMDrcKU3"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# perform data modeling\n",
        "def perform_data_modeling(_models_, _imputers_, verbose=False, k_folds=5):\n",
        "    \n",
        "    # 7 Models\n",
        "    # 4 Imputers\n",
        "    # 5 datasets (for 5 years)\n",
        "    # 7 metrics, averaged over all the K-Folds\n",
        "    model_results = OrderedDict()\n",
        "    \n",
        "    # Iterate over the models\n",
        "    for model_name, clf in _models_.items():\n",
        "        if verbose: print(\"-\"*120, \"\\n\", \"Model: \" + '\\033[1m' + model_name + '\\033[0m' + \" Classifier\")\n",
        "        imputer_results = OrderedDict()\n",
        "        \n",
        "        # Iterate over the different imputed_data mechanisms (Mean, k-NN, EM, MICE)\n",
        "        for imputer_name, dataframes_list in _imputers_.items():\n",
        "            if verbose: print('\\tImputer Technique: ' + '\\033[1m' + imputer_name + '\\033[0m')\n",
        "            \n",
        "            # call the split_dataframes_features_labels function to get a list of features and labels for all the dataframes\n",
        "            feature_dfs, label_dfs = split_dataframes_features_labels(dataframes_list)            \n",
        "            \n",
        "            year_results = OrderedDict()\n",
        "            \n",
        "            # Iterate over dataframe_list individually\n",
        "            for df_index in range(len(dataframes_list)):\n",
        "                if verbose: print('\\t\\tDataset: ' + '\\033[1m' + str(df_index+1) + 'year' + '\\033[0m')\n",
        "                \n",
        "                # Calling the 'prepare_kfold_cv_data' returns lists of features and labels \n",
        "                # for train and test sets respectively.\n",
        "                # The number of items in the list is equal to k_folds\n",
        "                X_train_list, y_train_list, X_test_list, y_test_list = prepare_kfold_cv_data(k_folds, feature_dfs[df_index], label_dfs[df_index], verbose)\n",
        "                \n",
        "                metrics_results = OrderedDict()\n",
        "                accuracy_list = np.zeros([k_folds])\n",
        "                precision_list = np.zeros([k_folds,2])\n",
        "                recall_list = np.zeros([k_folds,2])\n",
        "                TN_list = np.zeros([k_folds])\n",
        "                FP_list = np.zeros([k_folds])\n",
        "                FN_list = np.zeros([k_folds])\n",
        "                TP_list = np.zeros([k_folds])                \n",
        "                \n",
        "                # Iterate over all the k-folds\n",
        "                for k_index in range(k_folds):\n",
        "                    X_train = X_train_list[k_index]\n",
        "                    y_train = y_train_list[k_index]\n",
        "                    X_test = X_test_list[k_index]\n",
        "                    y_test = y_test_list[k_index]\n",
        "                    \n",
        "                    # Fit the model and \n",
        "                    clf = clf.fit(X_train, y_train)\n",
        "                    y_test_predicted = clf.predict(X_test)\n",
        "                    \n",
        "                    #code for calculating accuracy \n",
        "                    _accuracy_ = accuracy_score(y_test, y_test_predicted, normalize=True)\n",
        "                    accuracy_list[k_index] = _accuracy_\n",
        "                    \n",
        "                    #code for calculating recall \n",
        "                    _recalls_ = recall_score(y_test, y_test_predicted, average=None)\n",
        "                    recall_list[k_index] = _recalls_\n",
        "                    \n",
        "                    #code for calculating precision \n",
        "                    _precisions_ = precision_score(y_test, y_test_predicted, average=None)\n",
        "                    precision_list[k_index] = _precisions_\n",
        "                    \n",
        "                    #code for calculating confusion matrix \n",
        "                    _confusion_matrix_ = confusion_matrix(y_test, y_test_predicted)\n",
        "                    TN_list[k_index] = _confusion_matrix_[0][0]\n",
        "                    FP_list[k_index] = _confusion_matrix_[0][1]\n",
        "                    FN_list[k_index] = _confusion_matrix_[1][0]\n",
        "                    TP_list[k_index] = _confusion_matrix_[1][1]\n",
        "                \n",
        "                # creating a metrics dictionary\n",
        "                metrics_results['Accuracy'] = np.mean(accuracy_list)\n",
        "                metrics_results['Precisions'] = np.mean(precision_list, axis=0)\n",
        "                metrics_results['Recalls'] = np.mean(recall_list, axis=0)\n",
        "                metrics_results['TN'] = np.mean(TN_list)\n",
        "                metrics_results['FP'] = np.mean(FP_list)\n",
        "                metrics_results['FN'] = np.mean(FN_list)\n",
        "                metrics_results['TP'] = np.mean(TP_list)\n",
        "                \n",
        "                if verbose:\n",
        "                    print('\\t\\t\\tAccuracy:', metrics_results['Accuracy'])\n",
        "                    print('\\t\\t\\tPrecision:', metrics_results['Precisions'])\n",
        "                    print('\\t\\t\\tRecall:', metrics_results['Recalls'])\n",
        "                \n",
        "                year_results[str(df_index+1)+'year'] = metrics_results   \n",
        "                \n",
        "            imputer_results[imputer_name] = year_results\n",
        "            \n",
        "        model_results[model_name] = imputer_results  \n",
        "        \n",
        "    return model_results"
      ],
      "metadata": {
        "id": "bPjfgD3-cMhx"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = perform_data_modeling(models_dictionary, imputed_oversampled_dataframes_dictionary, verbose=True, k_folds=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAWLO0lMcTDI",
        "outputId": "f6157fe5-b21d-425e-f0bb-1a581d34ba65"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------------------------------------------------------ \n",
            " Model: \u001b[1mGaussian Naive Bayes\u001b[0m Classifier\n",
            "\tImputer Technique: \u001b[1mMean\u001b[0m\n",
            "\t\tDataset: \u001b[1m1year\u001b[0m\n",
            "\t\t\tAccuracy: 0.513025305928413\n",
            "\t\t\tPrecision: [0.75777557 0.50669387]\n",
            "\t\t\tRecall: [0.03818726 0.98789271]\n",
            "\t\tDataset: \u001b[1m2year\u001b[0m\n",
            "\t\t\tAccuracy: 0.513097455606087\n",
            "\t\t\tPrecision: [0.69693339 0.50678232]\n",
            "\t\t\tRecall: [0.04616108 0.98006004]\n",
            "\t\tDataset: \u001b[1m3year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5196842502987893\n",
            "\t\t\tPrecision: [0.74192611 0.51024965]\n",
            "\t\t\tRecall: [0.06062917 0.97869307]\n",
            "\t\tDataset: \u001b[1m4year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5121810367807227\n",
            "\t\t\tPrecision: [0.62025895 0.50641877]\n",
            "\t\t\tRecall: [0.06276721 0.96160451]\n",
            "\t\tDataset: \u001b[1m5year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5161818181818182\n",
            "\t\t\tPrecision: [0.6000262  0.56877141]\n",
            "\t\t\tRecall: [0.24508345 0.78762013]\n",
            "\tImputer Technique: \u001b[1mk-NN\u001b[0m\n",
            "\t\tDataset: \u001b[1m1year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5150974066427823\n",
            "\t\t\tPrecision: [0.76898429 0.50776655]\n",
            "\t\t\tRecall: [0.0431842  0.98699361]\n",
            "\t\tDataset: \u001b[1m2year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5119208279928475\n",
            "\t\t\tPrecision: [0.68392883 0.50617545]\n",
            "\t\t\tRecall: [0.04432885 0.97956727]\n",
            "\t\tDataset: \u001b[1m3year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5198341877957168\n",
            "\t\t\tPrecision: [0.72548639 0.51035864]\n",
            "\t\t\tRecall: [0.06432798 0.97527305]\n",
            "\t\tDataset: \u001b[1m4year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5118576738057833\n",
            "\t\t\tPrecision: [0.61647476 0.50624465]\n",
            "\t\t\tRecall: [0.06275987 0.96094536]\n",
            "\t\tDataset: \u001b[1m5year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5236363636363637\n",
            "\t\t\tPrecision: [0.64329205 0.57537863]\n",
            "\t\t\tRecall: [0.26002383 0.7876259 ]\n",
            "\tImputer Technique: \u001b[1mEM\u001b[0m\n",
            "\t\tDataset: \u001b[1m1year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5130250594714375\n",
            "\t\t\tPrecision: [0.74191958 0.506687  ]\n",
            "\t\t\tRecall: [0.03918377 0.98683159]\n",
            "\t\tDataset: \u001b[1m2year\u001b[0m\n",
            "\t\t\tAccuracy: 0.512176660981053\n",
            "\t\t\tPrecision: [0.66868331 0.5063095 ]\n",
            "\t\t\tRecall: [0.04849046 0.97582409]\n",
            "\t\tDataset: \u001b[1m3year\u001b[0m\n",
            "\t\t\tAccuracy: 0.527378230063716\n",
            "\t\t\tPrecision: [0.75878884 0.51444902]\n",
            "\t\t\tRecall: [0.08043373 0.97431083]\n",
            "\t\tDataset: \u001b[1m4year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5115342817775665\n",
            "\t\t\tPrecision: [0.61162251 0.50607934]\n",
            "\t\t\tRecall: [0.06285873 0.96019826]\n",
            "\t\tDataset: \u001b[1m5year\u001b[0m\n",
            "\t\t\tAccuracy: 0.517090909090909\n",
            "\t\t\tPrecision: [0.55971333 0.56188566]\n",
            "\t\t\tRecall: [0.28030181 0.75447296]\n",
            "------------------------------------------------------------------------------------------------------------------------ \n",
            " Model: \u001b[1mLogistic Regression\u001b[0m Classifier\n",
            "\tImputer Technique: \u001b[1mMean\u001b[0m\n",
            "\t\tDataset: \u001b[1m1year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5845167238857613\n",
            "\t\t\tPrecision: [0.55943802 0.65194268]\n",
            "\t\t\tRecall: [0.80074324 0.36699412]\n",
            "\t\tDataset: \u001b[1m2year\u001b[0m\n",
            "\t\t\tAccuracy: 0.565383209708856\n",
            "\t\t\tPrecision: [0.54520932 0.62773842]\n",
            "\t\t\tRecall: [0.80360124 0.32775332]\n",
            "\t\tDataset: \u001b[1m3year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5504595953634175\n",
            "\t\t\tPrecision: [0.53089262 0.64462186]\n",
            "\t\t\tRecall: [0.87551364 0.22554187]\n",
            "\t\tDataset: \u001b[1m4year\u001b[0m\n",
            "\t\t\tAccuracy: 0.6041819722962475\n",
            "\t\t\tPrecision: [0.58758415 0.63355398]\n",
            "\t\t\tRecall: [0.70836027 0.49993697]\n",
            "\t\tDataset: \u001b[1m5year\u001b[0m\n",
            "\t\t\tAccuracy: 0.6717272727272727\n",
            "\t\t\tPrecision: [0.66829294 0.67942571]\n",
            "\t\t\tRecall: [0.69174557 0.65103876]\n",
            "\tImputer Technique: \u001b[1mk-NN\u001b[0m\n",
            "\t\tDataset: \u001b[1m1year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5891092031689986\n",
            "\t\t\tPrecision: [0.56206172 0.66249599]\n",
            "\t\t\tRecall: [0.81467113 0.36337064]\n",
            "\t\tDataset: \u001b[1m2year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5766901091912623\n",
            "\t\t\tPrecision: [0.554081   0.63843777]\n",
            "\t\t\tRecall: [0.79422563 0.35921859]\n",
            "\t\tDataset: \u001b[1m3year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5587527012083594\n",
            "\t\t\tPrecision: [0.53625577 0.65970986]\n",
            "\t\t\tRecall: [0.87494466 0.24280587]\n",
            "\t\tDataset: \u001b[1m4year\u001b[0m\n",
            "\t\t\tAccuracy: 0.6155544127933201\n",
            "\t\t\tPrecision: [0.60709218 0.62736775]\n",
            "\t\t\tRecall: [0.65894523 0.57199708]\n",
            "\t\tDataset: \u001b[1m5year\u001b[0m\n",
            "\t\t\tAccuracy: 0.6885454545454545\n",
            "\t\t\tPrecision: [0.70598272 0.67455061]\n",
            "\t\t\tRecall: [0.64580362 0.73100591]\n",
            "\tImputer Technique: \u001b[1mEM\u001b[0m\n",
            "\t\tDataset: \u001b[1m1year\u001b[0m\n",
            "\t\t\tAccuracy: 0.6043530052552842\n",
            "\t\t\tPrecision: [0.58667188 0.63553614]\n",
            "\t\t\tRecall: [0.71878879 0.49144038]\n",
            "\t\tDataset: \u001b[1m2year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5819605749470531\n",
            "\t\t\tPrecision: [0.56522485 0.61125922]\n",
            "\t\t\tRecall: [0.71244556 0.45174596]\n",
            "\t\tDataset: \u001b[1m3year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5807349532805441\n",
            "\t\t\tPrecision: [0.56849537 0.59947324]\n",
            "\t\t\tRecall: [0.67111269 0.49081259]\n",
            "\t\tDataset: \u001b[1m4year\u001b[0m\n",
            "\t\t\tAccuracy: 0.6007869370655172\n",
            "\t\t\tPrecision: [0.6012098  0.60128901]\n",
            "\t\t\tRecall: [0.60159814 0.59984899]\n",
            "\t\tDataset: \u001b[1m5year\u001b[0m\n",
            "\t\t\tAccuracy: 0.6699999999999999\n",
            "\t\t\tPrecision: [0.73464164 0.63625331]\n",
            "\t\t\tRecall: [0.53862201 0.80145285]\n",
            "------------------------------------------------------------------------------------------------------------------------ \n",
            " Model: \u001b[1mDecision Tree\u001b[0m Classifier\n",
            "\tImputer Technique: \u001b[1mMean\u001b[0m\n",
            "\t\tDataset: \u001b[1m1year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9470093678296424\n",
            "\t\t\tPrecision: [0.95550859 0.93872975]\n",
            "\t\t\tRecall: [0.93779221 0.95635085]\n",
            "\t\tDataset: \u001b[1m2year\u001b[0m\n",
            "\t\t\tAccuracy: 0.929703948982576\n",
            "\t\t\tPrecision: [0.94170899 0.91836559]\n",
            "\t\t\tRecall: [0.91603179 0.9433113 ]\n",
            "\t\tDataset: \u001b[1m3year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9252100385250523\n",
            "\t\t\tPrecision: [0.93676485 0.91422302]\n",
            "\t\t\tRecall: [0.91198135 0.93847703]\n",
            "\t\tDataset: \u001b[1m4year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9187237621669677\n",
            "\t\t\tPrecision: [0.9327138  0.90562317]\n",
            "\t\t\tRecall: [0.90253648 0.93489864]\n",
            "\t\tDataset: \u001b[1m5year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9282727272727271\n",
            "\t\t\tPrecision: [0.93488353 0.92190703]\n",
            "\t\t\tRecall: [0.92070145 0.93576603]\n",
            "\tImputer Technique: \u001b[1mk-NN\u001b[0m\n",
            "\t\tDataset: \u001b[1m1year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9199228151520653\n",
            "\t\t\tPrecision: [0.931432   0.90897428]\n",
            "\t\t\tRecall: [0.90634786 0.93347075]\n",
            "\t\tDataset: \u001b[1m2year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9059137971982814\n",
            "\t\t\tPrecision: [0.92188747 0.89112031]\n",
            "\t\t\tRecall: [0.88688145 0.92489666]\n",
            "\t\tDataset: \u001b[1m3year\u001b[0m\n",
            "\t\t\tAccuracy: 0.896882507949208\n",
            "\t\t\tPrecision: [0.91210412 0.88271216]\n",
            "\t\t\tRecall: [0.87841582 0.91537552]\n",
            "\t\tDataset: \u001b[1m4year\u001b[0m\n",
            "\t\t\tAccuracy: 0.8956027138666208\n",
            "\t\t\tPrecision: [0.90936744 0.88273836]\n",
            "\t\t\tRecall: [0.87883244 0.91235427]\n",
            "\t\tDataset: \u001b[1m5year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9027272727272727\n",
            "\t\t\tPrecision: [0.91620734 0.89017421]\n",
            "\t\t\tRecall: [0.88648882 0.91891468]\n",
            "\tImputer Technique: \u001b[1mEM\u001b[0m\n",
            "\t\tDataset: \u001b[1m1year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9430870872153729\n",
            "\t\t\tPrecision: [0.95241691 0.93411632]\n",
            "\t\t\tRecall: [0.93280087 0.95333485]\n",
            "\t\tDataset: \u001b[1m2year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9238720403240211\n",
            "\t\t\tPrecision: [0.935596   0.91280159]\n",
            "\t\t\tRecall: [0.9104505  0.93721802]\n",
            "\t\tDataset: \u001b[1m3year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9177658090098759\n",
            "\t\t\tPrecision: [0.930386   0.90584209]\n",
            "\t\t\tRecall: [0.90310663 0.93250816]\n",
            "\t\tDataset: \u001b[1m4year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9103699716948448\n",
            "\t\t\tPrecision: [0.92371282 0.89790928]\n",
            "\t\t\tRecall: [0.89473579 0.92607533]\n",
            "\t\tDataset: \u001b[1m5year\u001b[0m\n",
            "\t\t\tAccuracy: 0.926818181818182\n",
            "\t\t\tPrecision: [0.93184969 0.92214977]\n",
            "\t\t\tRecall: [0.92099601 0.93246765]\n",
            "------------------------------------------------------------------------------------------------------------------------ \n",
            " Model: \u001b[1mExtreme Gradient Boosting\u001b[0m Classifier\n",
            "\tImputer Technique: \u001b[1mMean\u001b[0m\n",
            "\t\tDataset: \u001b[1m1year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9601090489964683\n",
            "\t\t\tPrecision: [0.95436864 0.96592292]\n",
            "\t\t\tRecall: [0.96644427 0.9538888 ]\n",
            "\t\tDataset: \u001b[1m2year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9482759897645868\n",
            "\t\t\tPrecision: [0.93949739 0.95744876]\n",
            "\t\t\tRecall: [0.95838783 0.9381199 ]\n",
            "\t\tDataset: \u001b[1m3year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9341025948820103\n",
            "\t\t\tPrecision: [0.92760706 0.94084299]\n",
            "\t\t\tRecall: [0.94174342 0.92649148]\n",
            "\t\tDataset: \u001b[1m4year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9285876403000912\n",
            "\t\t\tPrecision: [0.92724104 0.92993627]\n",
            "\t\t\tRecall: [0.93018271 0.92701867]\n",
            "\t\tDataset: \u001b[1m5year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9422727272727274\n",
            "\t\t\tPrecision: [0.94380624 0.94086221]\n",
            "\t\t\tRecall: [0.94074416 0.94369223]\n",
            "\tImputer Technique: \u001b[1mk-NN\u001b[0m\n",
            "\t\tDataset: \u001b[1m1year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9269539588247069\n",
            "\t\t\tPrecision: [0.93823326 0.91634764]\n",
            "\t\t\tRecall: [0.91416356 0.93987624]\n",
            "\t\tDataset: \u001b[1m2year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9104672736991622\n",
            "\t\t\tPrecision: [0.91909393 0.9021919 ]\n",
            "\t\t\tRecall: [0.9000892  0.92082338]\n",
            "\t\tDataset: \u001b[1m3year\u001b[0m\n",
            "\t\t\tAccuracy: 0.8990808217513189\n",
            "\t\t\tPrecision: [0.91007972 0.88867848]\n",
            "\t\t\tRecall: [0.88572627 0.91251741]\n",
            "\t\tDataset: \u001b[1m4year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9049262736775129\n",
            "\t\t\tPrecision: [0.91677955 0.89372154]\n",
            "\t\t\tRecall: [0.89071576 0.91918249]\n",
            "\t\tDataset: \u001b[1m5year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9256363636363636\n",
            "\t\t\tPrecision: [0.93452976 0.91709132]\n",
            "\t\t\tRecall: [0.91549657 0.93577152]\n",
            "\tImputer Technique: \u001b[1mEM\u001b[0m\n",
            "\t\tDataset: \u001b[1m1year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9520420740395092\n",
            "\t\t\tPrecision: [0.95568865 0.94840131]\n",
            "\t\t\tRecall: [0.94815722 0.95610406]\n",
            "\t\tDataset: \u001b[1m2year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9336946609535737\n",
            "\t\t\tPrecision: [0.93121989 0.93616616]\n",
            "\t\t\tRecall: [0.93656163 0.93083136]\n",
            "\t\tDataset: \u001b[1m3year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9231611755718676\n",
            "\t\t\tPrecision: [0.91863522 0.92776155]\n",
            "\t\t\tRecall: [0.92859209 0.91774883]\n",
            "\t\tDataset: \u001b[1m4year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9204489602921597\n",
            "\t\t\tPrecision: [0.91913653 0.92178257]\n",
            "\t\t\tRecall: [0.92209517 0.91881603]\n",
            "\t\tDataset: \u001b[1m5year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9429090909090909\n",
            "\t\t\tPrecision: [0.9377426  0.94825672]\n",
            "\t\t\tRecall: [0.94894443 0.9368759 ]\n",
            "------------------------------------------------------------------------------------------------------------------------ \n",
            " Model: \u001b[1mRandom Forest\u001b[0m Classifier\n",
            "\tImputer Technique: \u001b[1mMean\u001b[0m\n",
            "\t\tDataset: \u001b[1m1year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9726908692893522\n",
            "\t\t\tPrecision: [0.98008945 0.96548815]\n",
            "\t\t\tRecall: [0.96487292 0.98050676]\n",
            "\t\tDataset: \u001b[1m2year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9591730278150168\n",
            "\t\t\tPrecision: [0.96828344 0.95043135]\n",
            "\t\t\tRecall: [0.94941876 0.96888499]\n",
            "\t\tDataset: \u001b[1m3year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9499899426079791\n",
            "\t\t\tPrecision: [0.96260411 0.93806641]\n",
            "\t\t\tRecall: [0.93640558 0.96362068]\n",
            "\t\tDataset: \u001b[1m4year\u001b[0m\n",
            "\t\t\tAccuracy: 0.945240964249216\n",
            "\t\t\tPrecision: [0.96354001 0.92833703]\n",
            "\t\t\tRecall: [0.92552018 0.96497151]\n",
            "\t\tDataset: \u001b[1m5year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9440909090909091\n",
            "\t\t\tPrecision: [0.95295787 0.93562432]\n",
            "\t\t\tRecall: [0.93435074 0.95376646]\n",
            "\tImputer Technique: \u001b[1mk-NN\u001b[0m\n",
            "\t\tDataset: \u001b[1m1year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9494514826167049\n",
            "\t\t\tPrecision: [0.96297646 0.93662029]\n",
            "\t\t\tRecall: [0.93496337 0.96398932]\n",
            "\t\tDataset: \u001b[1m2year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9417780333795903\n",
            "\t\t\tPrecision: [0.95367046 0.93051347]\n",
            "\t\t\tRecall: [0.92863138 0.95485718]\n",
            "\t\tDataset: \u001b[1m3year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9291566165535687\n",
            "\t\t\tPrecision: [0.94942916 0.91062252]\n",
            "\t\t\tRecall: [0.90655361 0.95176323]\n",
            "\t\tDataset: \u001b[1m4year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9306889185716537\n",
            "\t\t\tPrecision: [0.94669502 0.91581232]\n",
            "\t\t\tRecall: [0.9127855  0.94855694]\n",
            "\t\tDataset: \u001b[1m5year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9313636363636364\n",
            "\t\t\tPrecision: [0.94538628 0.91817787]\n",
            "\t\t\tRecall: [0.91568863 0.94705743]\n",
            "\tImputer Technique: \u001b[1mEM\u001b[0m\n",
            "\t\tDataset: \u001b[1m1year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9601827670162795\n",
            "\t\t\tPrecision: [0.96779625 0.95280406]\n",
            "\t\t\tRecall: [0.95203303 0.96829895]\n",
            "\t\tDataset: \u001b[1m2year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9497082671701935\n",
            "\t\t\tPrecision: [0.95891009 0.94091487]\n",
            "\t\t\tRecall: [0.93953402 0.95980105]\n",
            "\t\tDataset: \u001b[1m3year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9415968992286754\n",
            "\t\t\tPrecision: [0.95728127 0.92692123]\n",
            "\t\t\tRecall: [0.92454275 0.95870275]\n",
            "\t\tDataset: \u001b[1m4year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9387735159041272\n",
            "\t\t\tPrecision: [0.9556866  0.92308705]\n",
            "\t\t\tRecall: [0.92023467 0.95729567]\n",
            "\t\tDataset: \u001b[1m5year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9394545454545454\n",
            "\t\t\tPrecision: [0.95416487 0.92579672]\n",
            "\t\t\tRecall: [0.9231771  0.95566621]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in range(len(dataframes)):\n",
        "#   print(np.any(np.isnan(dataframes[i])))"
      ],
      "metadata": {
        "id": "6eTAE_mycWBt"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in range(len(dataframes)):\n",
        "  # print(np.all(np.isfinite(dataframes[i])))"
      ],
      "metadata": {
        "id": "BSxSCo0chVc6"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model -> imputer -> year\n",
        "def perform_model_ranking(models, imputers, results):\n",
        "    column_headers = ['-'] + list(imputers.keys())\n",
        "    rows = []\n",
        "    for model_name, model_details in results.items():\n",
        "        row = [model_name]\n",
        "        for imputer_name, imputer_details in model_details.items():\n",
        "            mean_accuracy = 0\n",
        "            for year, metrics in imputer_details.items():\n",
        "                mean_accuracy += metrics['Accuracy']\n",
        "            mean_accuracy = mean_accuracy/len(imputer_details)\n",
        "            row.append(mean_accuracy)\n",
        "        rows.append(row)\n",
        "    results_df = pd.DataFrame(data=rows, columns = column_headers)\n",
        "    return results_df"
      ],
      "metadata": {
        "id": "2v5ZlQvzh0mv"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perform_model_ranking(models_dictionary, imputed_oversampled_dataframes_dictionary, results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FY_fsRVjuK6B",
        "outputId": "b8fa2d21-52e6-4e7a-90ce-126d2c54d986"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           -      Mean      k-NN        EM\n",
              "0       Gaussian Naive Bayes  0.514834  0.516469  0.516241\n",
              "1        Logistic Regression  0.595254  0.605730  0.607567\n",
              "2              Decision Tree  0.929784  0.904210  0.924383\n",
              "3  Extreme Gradient Boosting  0.942670  0.913413  0.934451\n",
              "4              Random Forest  0.954237  0.936488  0.945943"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-57beb290-42f2-41e9-bac6-046ee2392dd1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>-</th>\n",
              "      <th>Mean</th>\n",
              "      <th>k-NN</th>\n",
              "      <th>EM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Gaussian Naive Bayes</td>\n",
              "      <td>0.514834</td>\n",
              "      <td>0.516469</td>\n",
              "      <td>0.516241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.595254</td>\n",
              "      <td>0.605730</td>\n",
              "      <td>0.607567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>0.929784</td>\n",
              "      <td>0.904210</td>\n",
              "      <td>0.924383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Extreme Gradient Boosting</td>\n",
              "      <td>0.942670</td>\n",
              "      <td>0.913413</td>\n",
              "      <td>0.934451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.954237</td>\n",
              "      <td>0.936488</td>\n",
              "      <td>0.945943</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57beb290-42f2-41e9-bac6-046ee2392dd1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-57beb290-42f2-41e9-bac6-046ee2392dd1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-57beb290-42f2-41e9-bac6-046ee2392dd1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This list stores results of Balanced Bagging classifier obtained by running it for \n",
        "# various values of number of estimators in the range of 1 to 30\n",
        "results_by_estimators = []\n",
        "for i in range(29):\n",
        "    # models_dictionary['Balanced Bagging'] = BalancedBaggingClassifier(base_estimator = RandomForestClassifier(criterion='entropy'), n_estimators = i+1, bootstrap = True)\n",
        "    results = perform_data_modeling(models_dictionary, imputed_oversampled_dataframes_dictionary, verbose=True, k_folds=5)\n",
        "    results_by_estimators.append(results) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "h-wDoLeFugod",
        "outputId": "003c2daf-d565-4e37-a071-5677d660026b"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------------------------------------------------------ \n",
            " Model: \u001b[1mGaussian Naive Bayes\u001b[0m Classifier\n",
            "\tImputer Technique: \u001b[1mMean\u001b[0m\n",
            "\t\tDataset: \u001b[1m1year\u001b[0m\n",
            "\t\t\tAccuracy: 0.513025305928413\n",
            "\t\t\tPrecision: [0.75777557 0.50669387]\n",
            "\t\t\tRecall: [0.03818726 0.98789271]\n",
            "\t\tDataset: \u001b[1m2year\u001b[0m\n",
            "\t\t\tAccuracy: 0.513097455606087\n",
            "\t\t\tPrecision: [0.69693339 0.50678232]\n",
            "\t\t\tRecall: [0.04616108 0.98006004]\n",
            "\t\tDataset: \u001b[1m3year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5196842502987893\n",
            "\t\t\tPrecision: [0.74192611 0.51024965]\n",
            "\t\t\tRecall: [0.06062917 0.97869307]\n",
            "\t\tDataset: \u001b[1m4year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5121810367807227\n",
            "\t\t\tPrecision: [0.62025895 0.50641877]\n",
            "\t\t\tRecall: [0.06276721 0.96160451]\n",
            "\t\tDataset: \u001b[1m5year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5161818181818182\n",
            "\t\t\tPrecision: [0.6000262  0.56877141]\n",
            "\t\t\tRecall: [0.24508345 0.78762013]\n",
            "\tImputer Technique: \u001b[1mk-NN\u001b[0m\n",
            "\t\tDataset: \u001b[1m1year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5150974066427823\n",
            "\t\t\tPrecision: [0.76898429 0.50776655]\n",
            "\t\t\tRecall: [0.0431842  0.98699361]\n",
            "\t\tDataset: \u001b[1m2year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5119208279928475\n",
            "\t\t\tPrecision: [0.68392883 0.50617545]\n",
            "\t\t\tRecall: [0.04432885 0.97956727]\n",
            "\t\tDataset: \u001b[1m3year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5198341877957168\n",
            "\t\t\tPrecision: [0.72548639 0.51035864]\n",
            "\t\t\tRecall: [0.06432798 0.97527305]\n",
            "\t\tDataset: \u001b[1m4year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5118576738057833\n",
            "\t\t\tPrecision: [0.61647476 0.50624465]\n",
            "\t\t\tRecall: [0.06275987 0.96094536]\n",
            "\t\tDataset: \u001b[1m5year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5236363636363637\n",
            "\t\t\tPrecision: [0.64329205 0.57537863]\n",
            "\t\t\tRecall: [0.26002383 0.7876259 ]\n",
            "\tImputer Technique: \u001b[1mEM\u001b[0m\n",
            "\t\tDataset: \u001b[1m1year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5130250594714375\n",
            "\t\t\tPrecision: [0.74191958 0.506687  ]\n",
            "\t\t\tRecall: [0.03918377 0.98683159]\n",
            "\t\tDataset: \u001b[1m2year\u001b[0m\n",
            "\t\t\tAccuracy: 0.512176660981053\n",
            "\t\t\tPrecision: [0.66868331 0.5063095 ]\n",
            "\t\t\tRecall: [0.04849046 0.97582409]\n",
            "\t\tDataset: \u001b[1m3year\u001b[0m\n",
            "\t\t\tAccuracy: 0.527378230063716\n",
            "\t\t\tPrecision: [0.75878884 0.51444902]\n",
            "\t\t\tRecall: [0.08043373 0.97431083]\n",
            "\t\tDataset: \u001b[1m4year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5115342817775665\n",
            "\t\t\tPrecision: [0.61162251 0.50607934]\n",
            "\t\t\tRecall: [0.06285873 0.96019826]\n",
            "\t\tDataset: \u001b[1m5year\u001b[0m\n",
            "\t\t\tAccuracy: 0.517090909090909\n",
            "\t\t\tPrecision: [0.55971333 0.56188566]\n",
            "\t\t\tRecall: [0.28030181 0.75447296]\n",
            "------------------------------------------------------------------------------------------------------------------------ \n",
            " Model: \u001b[1mLogistic Regression\u001b[0m Classifier\n",
            "\tImputer Technique: \u001b[1mMean\u001b[0m\n",
            "\t\tDataset: \u001b[1m1year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5845167238857613\n",
            "\t\t\tPrecision: [0.55943802 0.65194268]\n",
            "\t\t\tRecall: [0.80074324 0.36699412]\n",
            "\t\tDataset: \u001b[1m2year\u001b[0m\n",
            "\t\t\tAccuracy: 0.565383209708856\n",
            "\t\t\tPrecision: [0.54520932 0.62773842]\n",
            "\t\t\tRecall: [0.80360124 0.32775332]\n",
            "\t\tDataset: \u001b[1m3year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5504595953634175\n",
            "\t\t\tPrecision: [0.53089262 0.64462186]\n",
            "\t\t\tRecall: [0.87551364 0.22554187]\n",
            "\t\tDataset: \u001b[1m4year\u001b[0m\n",
            "\t\t\tAccuracy: 0.6041819722962475\n",
            "\t\t\tPrecision: [0.58758415 0.63355398]\n",
            "\t\t\tRecall: [0.70836027 0.49993697]\n",
            "\t\tDataset: \u001b[1m5year\u001b[0m\n",
            "\t\t\tAccuracy: 0.6717272727272727\n",
            "\t\t\tPrecision: [0.66829294 0.67942571]\n",
            "\t\t\tRecall: [0.69174557 0.65103876]\n",
            "\tImputer Technique: \u001b[1mk-NN\u001b[0m\n",
            "\t\tDataset: \u001b[1m1year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5891092031689986\n",
            "\t\t\tPrecision: [0.56206172 0.66249599]\n",
            "\t\t\tRecall: [0.81467113 0.36337064]\n",
            "\t\tDataset: \u001b[1m2year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5766901091912623\n",
            "\t\t\tPrecision: [0.554081   0.63843777]\n",
            "\t\t\tRecall: [0.79422563 0.35921859]\n",
            "\t\tDataset: \u001b[1m3year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5587527012083594\n",
            "\t\t\tPrecision: [0.53625577 0.65970986]\n",
            "\t\t\tRecall: [0.87494466 0.24280587]\n",
            "\t\tDataset: \u001b[1m4year\u001b[0m\n",
            "\t\t\tAccuracy: 0.6155544127933201\n",
            "\t\t\tPrecision: [0.60709218 0.62736775]\n",
            "\t\t\tRecall: [0.65894523 0.57199708]\n",
            "\t\tDataset: \u001b[1m5year\u001b[0m\n",
            "\t\t\tAccuracy: 0.6885454545454545\n",
            "\t\t\tPrecision: [0.70598272 0.67455061]\n",
            "\t\t\tRecall: [0.64580362 0.73100591]\n",
            "\tImputer Technique: \u001b[1mEM\u001b[0m\n",
            "\t\tDataset: \u001b[1m1year\u001b[0m\n",
            "\t\t\tAccuracy: 0.6043530052552842\n",
            "\t\t\tPrecision: [0.58667188 0.63553614]\n",
            "\t\t\tRecall: [0.71878879 0.49144038]\n",
            "\t\tDataset: \u001b[1m2year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5819605749470531\n",
            "\t\t\tPrecision: [0.56522485 0.61125922]\n",
            "\t\t\tRecall: [0.71244556 0.45174596]\n",
            "\t\tDataset: \u001b[1m3year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5807349532805441\n",
            "\t\t\tPrecision: [0.56849537 0.59947324]\n",
            "\t\t\tRecall: [0.67111269 0.49081259]\n",
            "\t\tDataset: \u001b[1m4year\u001b[0m\n",
            "\t\t\tAccuracy: 0.6007869370655172\n",
            "\t\t\tPrecision: [0.6012098  0.60128901]\n",
            "\t\t\tRecall: [0.60159814 0.59984899]\n",
            "\t\tDataset: \u001b[1m5year\u001b[0m\n",
            "\t\t\tAccuracy: 0.6699999999999999\n",
            "\t\t\tPrecision: [0.73464164 0.63625331]\n",
            "\t\t\tRecall: [0.53862201 0.80145285]\n",
            "------------------------------------------------------------------------------------------------------------------------ \n",
            " Model: \u001b[1mDecision Tree\u001b[0m Classifier\n",
            "\tImputer Technique: \u001b[1mMean\u001b[0m\n",
            "\t\tDataset: \u001b[1m1year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9470093678296424\n",
            "\t\t\tPrecision: [0.95550859 0.93872975]\n",
            "\t\t\tRecall: [0.93779221 0.95635085]\n",
            "\t\tDataset: \u001b[1m2year\u001b[0m\n",
            "\t\t\tAccuracy: 0.929703948982576\n",
            "\t\t\tPrecision: [0.94170899 0.91836559]\n",
            "\t\t\tRecall: [0.91603179 0.9433113 ]\n",
            "\t\tDataset: \u001b[1m3year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9252100385250523\n",
            "\t\t\tPrecision: [0.93676485 0.91422302]\n",
            "\t\t\tRecall: [0.91198135 0.93847703]\n",
            "\t\tDataset: \u001b[1m4year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9187237621669677\n",
            "\t\t\tPrecision: [0.9327138  0.90562317]\n",
            "\t\t\tRecall: [0.90253648 0.93489864]\n",
            "\t\tDataset: \u001b[1m5year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9282727272727271\n",
            "\t\t\tPrecision: [0.93488353 0.92190703]\n",
            "\t\t\tRecall: [0.92070145 0.93576603]\n",
            "\tImputer Technique: \u001b[1mk-NN\u001b[0m\n",
            "\t\tDataset: \u001b[1m1year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9199228151520653\n",
            "\t\t\tPrecision: [0.931432   0.90897428]\n",
            "\t\t\tRecall: [0.90634786 0.93347075]\n",
            "\t\tDataset: \u001b[1m2year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9059137971982814\n",
            "\t\t\tPrecision: [0.92188747 0.89112031]\n",
            "\t\t\tRecall: [0.88688145 0.92489666]\n",
            "\t\tDataset: \u001b[1m3year\u001b[0m\n",
            "\t\t\tAccuracy: 0.896882507949208\n",
            "\t\t\tPrecision: [0.91210412 0.88271216]\n",
            "\t\t\tRecall: [0.87841582 0.91537552]\n",
            "\t\tDataset: \u001b[1m4year\u001b[0m\n",
            "\t\t\tAccuracy: 0.8956027138666208\n",
            "\t\t\tPrecision: [0.90936744 0.88273836]\n",
            "\t\t\tRecall: [0.87883244 0.91235427]\n",
            "\t\tDataset: \u001b[1m5year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9027272727272727\n",
            "\t\t\tPrecision: [0.91620734 0.89017421]\n",
            "\t\t\tRecall: [0.88648882 0.91891468]\n",
            "\tImputer Technique: \u001b[1mEM\u001b[0m\n",
            "\t\tDataset: \u001b[1m1year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9430870872153729\n",
            "\t\t\tPrecision: [0.95241691 0.93411632]\n",
            "\t\t\tRecall: [0.93280087 0.95333485]\n",
            "\t\tDataset: \u001b[1m2year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9238720403240211\n",
            "\t\t\tPrecision: [0.935596   0.91280159]\n",
            "\t\t\tRecall: [0.9104505  0.93721802]\n",
            "\t\tDataset: \u001b[1m3year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9177658090098759\n",
            "\t\t\tPrecision: [0.930386   0.90584209]\n",
            "\t\t\tRecall: [0.90310663 0.93250816]\n",
            "\t\tDataset: \u001b[1m4year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9103699716948448\n",
            "\t\t\tPrecision: [0.92371282 0.89790928]\n",
            "\t\t\tRecall: [0.89473579 0.92607533]\n",
            "\t\tDataset: \u001b[1m5year\u001b[0m\n",
            "\t\t\tAccuracy: 0.926818181818182\n",
            "\t\t\tPrecision: [0.93184969 0.92214977]\n",
            "\t\t\tRecall: [0.92099601 0.93246765]\n",
            "------------------------------------------------------------------------------------------------------------------------ \n",
            " Model: \u001b[1mExtreme Gradient Boosting\u001b[0m Classifier\n",
            "\tImputer Technique: \u001b[1mMean\u001b[0m\n",
            "\t\tDataset: \u001b[1m1year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9601090489964683\n",
            "\t\t\tPrecision: [0.95436864 0.96592292]\n",
            "\t\t\tRecall: [0.96644427 0.9538888 ]\n",
            "\t\tDataset: \u001b[1m2year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9482759897645868\n",
            "\t\t\tPrecision: [0.93949739 0.95744876]\n",
            "\t\t\tRecall: [0.95838783 0.9381199 ]\n",
            "\t\tDataset: \u001b[1m3year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9341025948820103\n",
            "\t\t\tPrecision: [0.92760706 0.94084299]\n",
            "\t\t\tRecall: [0.94174342 0.92649148]\n",
            "\t\tDataset: \u001b[1m4year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9285876403000912\n",
            "\t\t\tPrecision: [0.92724104 0.92993627]\n",
            "\t\t\tRecall: [0.93018271 0.92701867]\n",
            "\t\tDataset: \u001b[1m5year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9422727272727274\n",
            "\t\t\tPrecision: [0.94380624 0.94086221]\n",
            "\t\t\tRecall: [0.94074416 0.94369223]\n",
            "\tImputer Technique: \u001b[1mk-NN\u001b[0m\n",
            "\t\tDataset: \u001b[1m1year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9269539588247069\n",
            "\t\t\tPrecision: [0.93823326 0.91634764]\n",
            "\t\t\tRecall: [0.91416356 0.93987624]\n",
            "\t\tDataset: \u001b[1m2year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9104672736991622\n",
            "\t\t\tPrecision: [0.91909393 0.9021919 ]\n",
            "\t\t\tRecall: [0.9000892  0.92082338]\n",
            "\t\tDataset: \u001b[1m3year\u001b[0m\n",
            "\t\t\tAccuracy: 0.8990808217513189\n",
            "\t\t\tPrecision: [0.91007972 0.88867848]\n",
            "\t\t\tRecall: [0.88572627 0.91251741]\n",
            "\t\tDataset: \u001b[1m4year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9049262736775129\n",
            "\t\t\tPrecision: [0.91677955 0.89372154]\n",
            "\t\t\tRecall: [0.89071576 0.91918249]\n",
            "\t\tDataset: \u001b[1m5year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9256363636363636\n",
            "\t\t\tPrecision: [0.93452976 0.91709132]\n",
            "\t\t\tRecall: [0.91549657 0.93577152]\n",
            "\tImputer Technique: \u001b[1mEM\u001b[0m\n",
            "\t\tDataset: \u001b[1m1year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9520420740395092\n",
            "\t\t\tPrecision: [0.95568865 0.94840131]\n",
            "\t\t\tRecall: [0.94815722 0.95610406]\n",
            "\t\tDataset: \u001b[1m2year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9336946609535737\n",
            "\t\t\tPrecision: [0.93121989 0.93616616]\n",
            "\t\t\tRecall: [0.93656163 0.93083136]\n",
            "\t\tDataset: \u001b[1m3year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9231611755718676\n",
            "\t\t\tPrecision: [0.91863522 0.92776155]\n",
            "\t\t\tRecall: [0.92859209 0.91774883]\n",
            "\t\tDataset: \u001b[1m4year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9204489602921597\n",
            "\t\t\tPrecision: [0.91913653 0.92178257]\n",
            "\t\t\tRecall: [0.92209517 0.91881603]\n",
            "\t\tDataset: \u001b[1m5year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9429090909090909\n",
            "\t\t\tPrecision: [0.9377426  0.94825672]\n",
            "\t\t\tRecall: [0.94894443 0.9368759 ]\n",
            "------------------------------------------------------------------------------------------------------------------------ \n",
            " Model: \u001b[1mRandom Forest\u001b[0m Classifier\n",
            "\tImputer Technique: \u001b[1mMean\u001b[0m\n",
            "\t\tDataset: \u001b[1m1year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9683983007613058\n",
            "\t\t\tPrecision: [0.97388478 0.96294914]\n",
            "\t\t\tRecall: [0.96259716 0.974302  ]\n",
            "\t\tDataset: \u001b[1m2year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9620896625859794\n",
            "\t\t\tPrecision: [0.97142046 0.95311032]\n",
            "\t\t\tRecall: [0.9522322  0.97193032]\n",
            "\t\tDataset: \u001b[1m3year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9517387558731552\n",
            "\t\t\tPrecision: [0.96061106 0.94323651]\n",
            "\t\t\tRecall: [0.94214261 0.96132621]\n",
            "\t\tDataset: \u001b[1m4year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9421148461520025\n",
            "\t\t\tPrecision: [0.95695084 0.92822367]\n",
            "\t\t\tRecall: [0.92579077 0.95841829]\n",
            "\t\tDataset: \u001b[1m5year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9453636363636363\n",
            "\t\t\tPrecision: [0.95935204 0.9322037 ]\n",
            "\t\t\tRecall: [0.93023995 0.96049992]\n",
            "\tImputer Technique: \u001b[1mk-NN\u001b[0m\n",
            "\t\tDataset: \u001b[1m1year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9514502486887805\n",
            "\t\t\tPrecision: [0.96157927 0.9418627 ]\n",
            "\t\t\tRecall: [0.94039703 0.96240178]\n",
            "\t\tDataset: \u001b[1m2year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9444388613331816\n",
            "\t\t\tPrecision: [0.95792562 0.93175048]\n",
            "\t\t\tRecall: [0.92966028 0.95918665]\n",
            "\t\tDataset: \u001b[1m3year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9311552549374185\n",
            "\t\t\tPrecision: [0.94941236 0.91432132]\n",
            "\t\t\tRecall: [0.91090301 0.95145933]\n",
            "\t\tDataset: \u001b[1m4year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9292334365451005\n",
            "\t\t\tPrecision: [0.94782442 0.91216281]\n",
            "\t\t\tRecall: [0.9084444  0.94996836]\n",
            "\t\tDataset: \u001b[1m5year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9303636363636365\n",
            "\t\t\tPrecision: [0.94679503 0.91519395]\n",
            "\t\t\tRecall: [0.91222772 0.94841406]\n",
            "\tImputer Technique: \u001b[1mEM\u001b[0m\n",
            "\t\tDataset: \u001b[1m1year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9614409572608006\n",
            "\t\t\tPrecision: [0.96870872 0.95433497]\n",
            "\t\t\tRecall: [0.95376415 0.9692401 ]\n",
            "\t\tDataset: \u001b[1m2year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9528799236335063\n",
            "\t\t\tPrecision: [0.96477672 0.94162506]\n",
            "\t\t\tRecall: [0.93994755 0.96574074]\n",
            "\t\tDataset: \u001b[1m3year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9428957253089154\n",
            "\t\t\tPrecision: [0.95522124 0.93121478]\n",
            "\t\t\tRecall: [0.92938996 0.95652206]\n",
            "\t\tDataset: \u001b[1m4year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9358633217628658\n",
            "\t\t\tPrecision: [0.95082134 0.92193121]\n",
            "\t\t\tRecall: [0.91927    0.95246651]\n",
            "\t\tDataset: \u001b[1m5year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9373636363636363\n",
            "\t\t\tPrecision: [0.95042497 0.92510234]\n",
            "\t\t\tRecall: [0.9229317  0.95177898]\n",
            "------------------------------------------------------------------------------------------------------------------------ \n",
            " Model: \u001b[1mBalanced Bagging\u001b[0m Classifier\n",
            "\tImputer Technique: \u001b[1mMean\u001b[0m\n",
            "\t\tDataset: \u001b[1m1year\u001b[0m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-f0c0e931a234>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m29\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# models_dictionary['Balanced Bagging'] = BalancedBaggingClassifier(base_estimator = RandomForestClassifier(criterion='entropy'), n_estimators = i+1, bootstrap = True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperform_data_modeling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels_dictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimputed_oversampled_dataframes_dictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mresults_by_estimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-77-e515c45fa1db>\u001b[0m in \u001b[0;36mperform_data_modeling\u001b[0;34m(_models_, _imputers_, verbose, k_folds)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                     \u001b[0;31m# Fit the model and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m                     \u001b[0my_test_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/imblearn/ensemble/_bagging.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;31m# RandomUnderSampler is not supporting sample_weight. We need to pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;31m# None.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_bagging.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, max_samples, max_depth, sample_weight)\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0mmax_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m             \u001b[0mmax_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_features\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"max_features must be int or float\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'BalancedBaggingClassifier' object has no attribute 'n_features_in_'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(results_by_estimators)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7SMJxfuxJbW",
        "outputId": "02695337-e0c4-4745-c4d7-a3c782ff94bc"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "year1_values = []\n",
        "year2_values = []\n",
        "year3_values = []\n",
        "year4_values = []\n",
        "year5_values = []\n",
        "\n",
        "# extract corresponding Balanced bagging with Mean imputation\n",
        "# classification metrics \n",
        "def extract_actual_values_from_dict(curr_dict):\n",
        "    temp_dict = curr_dict['Balanced Bagging']\n",
        "    return temp_dict['Mean']\n",
        "\n",
        "for i in range(29):\n",
        "    curr_dict = results_by_estimators[i]\n",
        "    curr_result = extract_actual_values_from_dict(curr_dict)\n",
        "    \n",
        "        \n",
        "    year_1_result = curr_result['1year']\n",
        "    year_2_result = curr_result['2year']\n",
        "    year_3_result = curr_result['3year']\n",
        "    year_4_result = curr_result['4year']\n",
        "    year_5_result = curr_result['5year']\n",
        "    year1_values.append(year_1_result['Accuracy'])\n",
        "    year2_values.append(year_2_result['Accuracy'])\n",
        "    year3_values.append(year_3_result['Accuracy'])\n",
        "    year4_values.append(year_4_result['Accuracy'])\n",
        "    year5_values.append(year_5_result['Accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "-v2Cu0auuZxZ",
        "outputId": "7f7877c5-1f32-44c4-96d6-6982a125808c"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-cb83c338bbbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m29\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mcurr_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_by_estimators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mcurr_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_actual_values_from_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "estimators = [i+1 for i in range(29)] \n",
        "\n",
        "# plot year1, year2, year3, year4 and year5 accuracy values\n",
        "# for range of estimator values from 1 to 30\n",
        "plt.plot(estimators, year1_values, '.b-')\n",
        "plt.plot(estimators, year2_values, '.r-')\n",
        "plt.plot(estimators, year3_values, '.y-')\n",
        "plt.plot(estimators, year4_values, '.g-')\n",
        "plt.plot(estimators, year5_values, '.m-') \n",
        "plt.xlabel(\"\\nNumber of estimators\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"\\nEffect of varying number of estimators on the accuracy scores on different datasets\\n\")\n",
        "\n",
        "# display legend\n",
        "plt.plot(10, 0.93, '.b-', label='Year 1')\n",
        "plt.plot(10, 0.93, '.r-', label='Year 2')\n",
        "plt.plot(10, 0.93, '.y-', label='Year 3')\n",
        "plt.plot(10, 0.93, '.g-', label='Year 4')\n",
        "plt.plot(10, 0.93, '.m-', label='Year 5')\n",
        "\n",
        "plt.legend(loc='lower right')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "4yVBAR3yuNaG",
        "outputId": "48a129a7-a913-4c51-c163-09aa7ebc3004"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-9ab0d3f04650>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# plot year1, year2, year3, year4 and year5 accuracy values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# for range of estimator values from 1 to 30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear1_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.b-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear2_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.r-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear3_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.y-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2761\u001b[0m     return gca().plot(\n\u001b[1;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2763\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1645\u001b[0m         \"\"\"\n\u001b[1;32m   1646\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1647\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1648\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    343\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (29,) and (0,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QfSv0-HLuVdJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}